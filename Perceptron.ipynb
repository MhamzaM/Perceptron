{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb4454a-2066-4df0-ab45-8edb61783c8b",
   "metadata": {},
   "source": [
    "# What is a Perceptron\n",
    "A perceptron is a building block of neural network. \n",
    "\n",
    "A single perceptron is capable to classify an input into two classes (Binary classifier i-e 0 / 1).\n",
    "![A perceptron looks like this.](./perceptron_node.png \"Perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c87fa-45cb-47ee-bf78-b9518ad262b4",
   "metadata": {},
   "source": [
    "## Different parts of a perceptron:\n",
    "\n",
    "1. Input features (X) from dataset.\n",
    "2. Weights (W), one for each input feature and a bias B.\n",
    "3. A Net input Function.\n",
    "4. Activation Function to normalize the values between (0 - 1).\n",
    "5. Output (0/1 or Yes/No or Dog/ Cat etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7e38c-c877-49e6-8174-7bcf043fcacd",
   "metadata": {},
   "source": [
    "## Sonar Dataset\n",
    "\n",
    "Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time. The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.\n",
    "\n",
    "The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder). The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a98b402-8f2c-482e-a8cd-0624ab239787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "84e3c1ed-1008-4a02-b3f8-d7f01d968d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [i for i in range(1,61)]\n",
    "columns.append(\"label\")\n",
    "df = pd.read_csv(\"sonar.all-data\",delimiter = \",\",names = columns,header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fe21a357-44f5-42fb-b343-60309d150c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1       2       3       4       5       6       7       8       9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       10  ...      52      53      54      55      56      57      58  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       59      60  label  \n",
       "0  0.0090  0.0032      R  \n",
       "1  0.0052  0.0044      R  \n",
       "2  0.0095  0.0078      R  \n",
       "3  0.0040  0.0117      R  \n",
       "4  0.0107  0.0094      R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d7f74-994a-4f2b-9365-466ca1b6fccc",
   "metadata": {},
   "source": [
    "Replacing R with 0 and M with 1 as our perceptron can only deal with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "baba7954-fd00-4828-bc3d-cde76abd9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].replace({'R': 0, 'M': 1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "56116ad1-2b87-4fd0-ba6b-d954a9c60fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[columns[:-1]], df[columns[-1]], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5896d18f-931a-45f8-a8f7-62da3b511850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1       2       3       4       5       6       7       8       9   \\\n",
       "28   0.0100  0.0275  0.0190  0.0371  0.0416  0.0201  0.0314  0.0651  0.1896   \n",
       "42   0.0211  0.0319  0.0415  0.0286  0.0121  0.0438  0.1299  0.1390  0.0695   \n",
       "79   0.0108  0.0086  0.0058  0.0460  0.0752  0.0887  0.1015  0.0494  0.0472   \n",
       "97   0.0491  0.0279  0.0592  0.1270  0.1772  0.1908  0.2217  0.0768  0.1246   \n",
       "142  0.0526  0.0563  0.1219  0.1206  0.0246  0.1022  0.0539  0.0439  0.2291   \n",
       "\n",
       "         10  ...      51      52      53      54      55      56      57  \\\n",
       "28   0.2668  ...  0.0118  0.0088  0.0104  0.0036  0.0088  0.0047  0.0117   \n",
       "42   0.0568  ...  0.0053  0.0090  0.0042  0.0153  0.0106  0.0020  0.0105   \n",
       "79   0.0393  ...  0.0161  0.0029  0.0078  0.0114  0.0083  0.0058  0.0003   \n",
       "97   0.2028  ...  0.0268  0.0081  0.0129  0.0161  0.0063  0.0119  0.0194   \n",
       "142  0.1632  ...  0.0380  0.0339  0.0149  0.0335  0.0376  0.0174  0.0132   \n",
       "\n",
       "         58      59      60  \n",
       "28   0.0020  0.0091  0.0058  \n",
       "42   0.0049  0.0070  0.0080  \n",
       "79   0.0023  0.0026  0.0027  \n",
       "97   0.0140  0.0332  0.0439  \n",
       "142  0.0103  0.0364  0.0208  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04124abc-bbbd-4125-b6c0-f04721bc5d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161    1\n",
       "15     0\n",
       "73     0\n",
       "96     0\n",
       "166    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "299e193f-9923-4c43-9669-f5213866481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0bca29f5-88f3-4279-b955-0e6d96f7697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 60)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13de9a2-4990-4ce3-932f-81410f56fca2",
   "metadata": {},
   "source": [
    "## Weights\n",
    "Let's initialize Weights for each input feature. We have 60 features so we need to define 60 wieghts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dd5b3b8e-aa9b-41e4-aa24-880a0736d8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(60,1)\n",
    "print(W.shape)\n",
    "#W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178913b8-4890-4075-afd9-7b3a432bec48",
   "metadata": {},
   "source": [
    "## Bias\n",
    "Let's initialize Bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "167e32ae-6e5a-45ca-bd0a-e942ccc19bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11876666])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.rand(1)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e82abf-4a22-4e6a-a090-a4c796e8e6b0",
   "metadata": {},
   "source": [
    "## Forward Pass\n",
    "Forward pass contains two steps:\n",
    "1. **Net Input Function:** where we multiply each feature x with it's corresponding weight w and then sum all of the resulting values to get a single value Z. \n",
    "2. **Activation Function:** Applying activaton funciton on Z.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf207ee-ca28-4dab-aaa2-113b0d70ead1",
   "metadata": {},
   "source": [
    "### Net Input Function\n",
    "We have to comput the Net Input Function for all the training samples.\n",
    "\n",
    "\n",
    "![Net input function.](./NIF.png \"Net input function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9d6b0683-fb48-4141-ade6-1440c8658097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 139)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.T\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9d6ecccb-4654-44f1-8b85-0d90553a1555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "58fd09a3-d035-436e-971e-1f84f33cee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfTrainSamples = X_train.shape[1]\n",
    "numOfFeatures = X_train.shape[0]\n",
    "Z = np.zeros(numOfTrainSamples)\n",
    "\n",
    "for i in range(numOfTrainSamples):\n",
    "    for j in range(numOfFeatures): \n",
    "        z = float(X_train[j][i] * W[j])\n",
    "        Z[i] = Z[i]+z\n",
    "    Z[i] = Z[i] + b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e1e866e1-f840-4a19-99af-d530fd86ffb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f5fbf00e-0a33-435a-b570-3e1ade618f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.92819306, 10.15527821,  7.59577711,  8.04463496,  9.51819517])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7468c0d-f8a0-42bb-8528-ab0da92439da",
   "metadata": {},
   "source": [
    "Same net input function can be computed in an optimized manner by using vectorized code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "773ec026-8e6a-4405-aee4-9a80d6e7f879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "01adc718-e282-4e7f-85d4-5fd9aaed08ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 139)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d6b4633f-91fa-48b4-85c2-2f257ca20283",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.dot(W.T,X_train) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0cd9f08a-a6af-41aa-9bed-06bd4475e83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 139)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "61a26eb7-123c-4a1d-af04-5bfdc80be4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.92819306, 10.15527821,  7.59577711,  8.04463496,  9.51819517])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[0,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2771418-b3a3-4164-9e76-b1d1858d9e3f",
   "metadata": {},
   "source": [
    "### Activation Funciton\n",
    "We apply activation function to normalize the output values between 0 and 1.\n",
    "Most commonly used Activation Functions are:\n",
    "1. Sigmoid\n",
    "2. Relu\n",
    "3. Leaky Relu\n",
    "4. tanh and more\n",
    "\n",
    "We will use sigmoid for our example.\n",
    "\n",
    "\n",
    "![Sigmoid function.](./sigmoid.png \"Sigmoid Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "de62a42a-2f87-41fe-9a70-cfdcdbe72828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "654f5925-cde5-4b29-b6ac-56bccfc21a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [sigmoid(z) for z in Z[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2c5564b4-0047-4e4e-ab0e-6459e96745de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9996396927548882,\n",
       " 0.9999611311375289,\n",
       " 0.9994976831959804,\n",
       " 0.999679284375272,\n",
       " 0.9999265031986572]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0104085-eb20-4939-a9ee-d3fe23ea2760",
   "metadata": {},
   "source": [
    "More optimized way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a5a050f8-395f-46e8-9672-43d6189120f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b9cd1c49-c643-4eb9-97ee-eafa1ba2e362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99963969, 0.99996113, 0.99949768, 0.99967928, 0.9999265 ])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d8a4f-1a88-449a-a2df-564340f80edc",
   "metadata": {},
   "source": [
    "### What's Next?\n",
    "We have computed the output values, now what to do with them? We need the perceptron to answer in Rock / Mine or in other words 0 / 1.\n",
    "We need to apply a threshold on the output values. In most cases a threshold of 0.5 is used. All the output values greater than 0.5 will be considered as 1 and less than 0.5 will be considered as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "51f773cd-992b-48ee-ae9d-229858b069bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.where(A < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "411e6627-926e-4997-9aaa-ff1f15a17629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "caae408d-8769-43aa-ab86-e1f4a3080d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9885edc1-d53e-4023-ae2d-65ffe2af86fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139,)\n",
      "(1, 139)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9f7c6825-2fc6-4394-b722-78ebe67b335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.expand_dims(y_train,axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b0ace564-e220-4581-8c6c-c7147963958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 139)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd8736-a92b-4ae4-8046-b8f0b12f5bdf",
   "metadata": {},
   "source": [
    "## Output Analysis\n",
    "Our perceptron has not properly categorized the input. We have a lot of errors in it. Let's correct our perceptron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a6c86-e4ca-44f1-86ba-30764e097ea1",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "In Back propagation we compute errors / loss/ cost using a loss function and then tell each weight that how much it has contributed in the error which is done by taking partial derivative of Loss function with respect to each weight. \n",
    "\n",
    "### Error Functions:\n",
    "1. Mean Error Loss\n",
    "2. Mean Squared Error \n",
    "3. Mean Absolute Error\n",
    "4. Mean Squared Logarithmic Error Loss (MSLE)\n",
    "5. Mean Percentage Error\n",
    "6. Mean Absolute Percentage Error\n",
    "7. Binary Classification Losses Binary Cross Entropy\n",
    "8. Multi-Class Cross-Entropy\n",
    "9. Squared Hinge Loss\n",
    "10. Hinge Loss\n",
    "\n",
    "\n",
    "For our example we will be using Binary Cross Entropy Loss:\n",
    "![Binary cross entropy loss.](./loss.png \"Loss function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bf66aa37-453c-4b2c-88ac-0df6397dd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(A, Y):\n",
    "    return -(Y * np.log(A) + (1 - Y) * np.log(1 - A)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1dec07dc-997a-4160-864e-434b963e6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-127-f812bb7d02b5>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  return -(Y * np.log(A) + (1 - Y) * np.log(1 - A)).mean()\n",
      "<ipython-input-127-f812bb7d02b5>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -(Y * np.log(A) + (1 - Y) * np.log(1 - A)).mean()\n"
     ]
    }
   ],
   "source": [
    "J = binary_cross_entropy(A, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb4eec-bc34-45a9-b407-bfcddd8b34a1",
   "metadata": {},
   "source": [
    "Our implementation of loss function cannot handle log of 0 which is equal to 1 ( log(0) = 1 ), that's why we will use library function for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "96b131f0-367e-4806-8329-d6feaf872834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "J = log_loss(y_train,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "00966af3-7603-41b8-b1ff-25df2b88f9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360.21659711854045"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "attachments": {
    "a96160d5-023c-46cb-92f5-64d680542d74.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ea4bc681-e357-47e1-8c48-4050f17275ac",
   "metadata": {},
   "source": [
    "![dw.png](attachment:a96160d5-023c-46cb-92f5-64d680542d74.png)## Computing Gradients/ Slopes/ Derivatives\n",
    "Below are the partial derivatives of Loss function.\n",
    "\n",
    "![dz.](./dz.png \"dz\")\n",
    "\n",
    "![dw.](./dw.png \"dw\")\n",
    "\n",
    "![db.](./db.png \"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f887cb69-dec0-4a2c-8f13-3cba0d5f19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = A - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "221da50b-94d9-4de7-88d6-ae0a84616fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 139)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8d9f7fbf-5e36-4566-ac83-b56525d51972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 139)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67de72f-71b7-4c3f-b5ae-476c5680aa8e",
   "metadata": {},
   "source": [
    "We need to compute derivative of each weight for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d4f40575-f3f4-4635-a99c-9b4fb5255f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = np.zeros(len(W))\n",
    "for i in range(len(W)):\n",
    "    for j in range(X_train.shape[1]):\n",
    "        #print(str(i)+ \" \"+ str(j))\n",
    "        #print(X_train[i][j])\n",
    "        dw[i] = dw[i] + dz[0][j]*X_train[i][j]\n",
    "    dw[i] = dw[i]/X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3faad236-f236-485f-9d51-54479642da4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0104705 , 0.0154964 , 0.01788489, 0.02003237, 0.03098993])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f9aa0a0f-68c3-4eba-bb22-730c75e85663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfTrainSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f75fca-b55b-4e54-a39b-89dfcb400063",
   "metadata": {},
   "source": [
    "More optimized way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "81de314d-e6e3-4cd6-8516-3cedfc106292",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw =  np.dot(X_train,dz.T)/numOfTrainSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "98807932-c7b3-4301-afe9-d6e785883d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0104705 ],\n",
       "       [0.0154964 ],\n",
       "       [0.01788489],\n",
       "       [0.02003237],\n",
       "       [0.03098993]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e32224-3e72-408f-9b7b-b23ed7b6186a",
   "metadata": {},
   "source": [
    "For bias we need just need the mean of sum of all dz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1a1a524d-a517-462e-8dd1-5b03b193d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = np.sum(dz,axis =1)/numOfTrainSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f8d77229-5384-42e8-94c4-5383d6e225a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47482014])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758400c-73b4-4c22-987c-4c4242b13509",
   "metadata": {},
   "source": [
    "## Gradient Desent Step\n",
    "Now we will update all the weights according to their slopes.\n",
    "\n",
    "**Learning Rate (alpha)**\n",
    "alpha is used to control the gradients, if we keep the alpha too high our gradients will diverge from minimum and if we take the alpha too low, the gradients will converge to minimum slowly.\n",
    "\n",
    "alpha range [0,1]\n",
    "\n",
    "let's suppose alpha is 0.001\n",
    "\n",
    "### Update formulas for weight and bias\n",
    "\n",
    "![w_update.](./w_update.png \"w_update\")\n",
    "\n",
    "\n",
    "![b_update.](./b_update.png \"b_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "26bdd29a-d413-4d85-b526-f517722eb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "57d442b8-1700-4923-9e57-cdfe80c8c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W - alpha * dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6cdf6512-285e-4bc4-ab03-e75e6b26c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b - alpha *db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878fd66-0493-40c1-9e11-9a04fbf861eb",
   "metadata": {},
   "source": [
    "## Epoch\n",
    "1 Forward and 1 Backward pass is known as 1 epoch.\n",
    "\n",
    "## Task\n",
    "1. Write code to perform N number of epochs until the loss gets close to zero.\n",
    "2. Compute the loss after each epcoh using sklearn loss function.\n",
    "3. Once the perceptron gets trained, test the trained perceptron on testing data and report test accuracy, confusion matrix.\n",
    "4. Try different values of alpha and see how it affects the training process.\n",
    "5. Use the above vectorized code to make 2 layer Neural Network. 1st layer will contain 2 Perceptrons and last layer will contain 1 perceptron. See how it affects the performance using accuracy and confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f1d41e12-72de-4851-a9bb-f5d1ab1d814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n",
      "360.21659711854045\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "for i in range(100):\n",
    "    #Forward Pass\n",
    "    Z = np.dot(W.T,X_train,) + b\n",
    "    A = sigmoid(Z)\n",
    "    A = np.where(A < 0.5, 0, 1)\n",
    "\n",
    "    #Backward Pass\n",
    "    J = log_loss(y_train,A)\n",
    "    print(J)\n",
    "    dz = A - y_train\n",
    "    dw =  np.dot(X_train,dz.T)/numOfTrainSamples\n",
    "    db = np.sum(dz,axis =1)/numOfTrainSamples\n",
    "    W = W - alpha * dw\n",
    "    b = b - alpha *db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c86ebe7-b62e-4899-956e-a0d9416bd384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 69)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.T\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7631b25-2b90-446e-9b71-34033db9ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.dot(W.T,X_test,) + b\n",
    "A = sigmoid(Z)\n",
    "A = np.where(A < 0.5, 0, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dcfe03e3-8dfe-485b-b24d-8b24346285fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "28a9cb52-50b3-4c64-90eb-003aea01725a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 69)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3ee0c985-bcb9-48a9-8199-89d9bee3259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.expand_dims(y_test,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f40e4e2e-eb36-44b3-a34e-703f4466009f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 69)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b8110-f2fb-472d-9594-58cb33b994fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
